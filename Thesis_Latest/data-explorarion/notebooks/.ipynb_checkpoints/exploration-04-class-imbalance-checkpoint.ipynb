{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globally useful imports of standard libraries needed in this notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# import project specific modules used in this notebook\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "import mindwandering.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mindwandering Dealing with Class Imbalance \n",
    "\n",
    "The target label class is relatively imbalanced for this dataset.  Not as bad a some, but a bit.\n",
    "\n",
    "We will need the features and labels again to treat class imbalance.  Lets use the standard scaled features\n",
    "for our development of replicating the methods of dealing with class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use the standard scaled features in this notebook\n",
    "df_features = mindwandering.data.get_df_features()\n",
    "df_features_standard_scaled = mindwandering.data.transform_df_features_standard_scaled(df_features)\n",
    "\n",
    "# We also need the label data as it is the imbalanced target labels that we need\n",
    "# to balance the data of.\n",
    "# we only need the binary mind_wandered_label for this \n",
    "df_label = mindwandering.data.get_df_label()\n",
    "df_label = df_label.mind_wandered_label.copy()\n",
    "\n",
    "# we need the participiant_id field to perform leave-one-out group cross validation\n",
    "df_experiment_metadata = mindwandering.data.get_df_experiment_metadata()\n",
    "participant_id = df_experiment_metadata.participant_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets confirm the imbalance present in our mind_wandered_label target value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    2963\n",
       "True     1113\n",
       "Name: mind_wandered_label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count up the true and false values in our target label\n",
    "df_label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So approximately 27% of the targets are the positive label, and 73% are the negative label.  In the reference paper they used two methods,\n",
    "simple downsampling of the majority class, and Synthetic Minority Oversampling Technique (SMOTE) upsampling, which is a kind of data\n",
    "augmentation technique that imputes new training data instances using existing instances.  In this case it imputes from the minority\n",
    "class to increase their representation in a training set.  I believe that SMOTE does simple interpolation between a small sample of\n",
    "instances to create new instances with features somewhere between existing instances.\n",
    "\n",
    "Both of these methods are available in standard scikit-learn at the time of this project work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Majority Class Downsampling to Balance Classes\n",
    "\n",
    "Lets test out majority class downsampling.  We will be using leave-one-participant-out cross validation.  So lets develop some of that\n",
    "workflow here.  We will remove one participant's trials for testing, then downsample on the remaining training data and examine the results.\n",
    "\n",
    "Actually scikit-learn seams to have support for group based cross validation \n",
    "\n",
    "[Cross Validation Iterators for Grouped Data](https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation-iterators-for-grouped-data)\n",
    "\n",
    "Lets see if we can get that to work the way we need for our data, where each participant can have from 4 to 57 trials in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports needed for this section of the notebook\n",
    "from sklearn.model_selection import LeaveOneGroupOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3 4 5 6] [0 1]\n",
      "[0 1 4 5 6] [2 3]\n",
      "[0 1 2 3] [4 5 6]\n"
     ]
    }
   ],
   "source": [
    "# the small example of LeaveOneGroupOut from the scikit-learn documentation\n",
    "X = [1, 5, 10, 50, 60, 70, 80]\n",
    "y = [0, 1, 1, 2, 2, 2, 2]\n",
    "groups = [1, 1, 2, 2, 3, 3, 3]\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "for train, test in logo.split(X, y, groups=groups):\n",
    "    print(\"%s %s\" % (train, test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is returned here are actually indexes you can use to extact the trials from the X inputs and y outputs (assuming you had a numpy array or\n",
    "pandas dataframe you could index using an array of indices.\n",
    "\n",
    "Our groups will be the participant_ids.  Lets try it out with our features and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_idxs, test_idxs in logo.split(df_features_standard_scaled, df_label, groups=participant_id):\n",
    "    #print(type(train))\n",
    "    #print(type(test))\n",
    "    # uncomment to see the participant that was selected for the test\n",
    "    #print(participant_id.iloc[test])\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This does appear to be working as needed.  We are getting numpy arrays.  The arrays will work to index only the rows we want from the features and\n",
    "label dataframes to split out the train and test data.\n",
    "\n",
    "Back to downsampling.  Lets create a logo and get the first participant train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51]\n",
      "1     1002-UM\n",
      "2     1002-UM\n",
      "3     1002-UM\n",
      "4     1002-UM\n",
      "5     1002-UM\n",
      "6     1002-UM\n",
      "7     1002-UM\n",
      "8     1002-UM\n",
      "9     1002-UM\n",
      "10    1002-UM\n",
      "11    1002-UM\n",
      "12    1002-UM\n",
      "13    1002-UM\n",
      "14    1002-UM\n",
      "15    1002-UM\n",
      "16    1002-UM\n",
      "17    1002-UM\n",
      "18    1002-UM\n",
      "19    1002-UM\n",
      "20    1002-UM\n",
      "21    1002-UM\n",
      "22    1002-UM\n",
      "23    1002-UM\n",
      "24    1002-UM\n",
      "25    1002-UM\n",
      "26    1002-UM\n",
      "27    1002-UM\n",
      "28    1002-UM\n",
      "29    1002-UM\n",
      "30    1002-UM\n",
      "31    1002-UM\n",
      "32    1002-UM\n",
      "33    1002-UM\n",
      "34    1002-UM\n",
      "35    1002-UM\n",
      "36    1002-UM\n",
      "37    1002-UM\n",
      "38    1002-UM\n",
      "39    1002-UM\n",
      "40    1002-UM\n",
      "41    1002-UM\n",
      "42    1002-UM\n",
      "43    1002-UM\n",
      "44    1002-UM\n",
      "45    1002-UM\n",
      "46    1002-UM\n",
      "47    1002-UM\n",
      "48    1002-UM\n",
      "49    1002-UM\n",
      "50    1002-UM\n",
      "51    1002-UM\n",
      "52    1002-UM\n",
      "Name: participant_id, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# extract test and train dataframes\n",
    "logo = LeaveOneGroupOut()\n",
    "logo_generator = logo.split(df_features_standard_scaled, df_label, groups=participant_id)\n",
    "train_idxs, test_idxs = next(logo_generator)\n",
    "print(test_idxs)\n",
    "print(participant_id.iloc[test_idxs])\n",
    "\n",
    "df_features_test = df_features_standard_scaled.iloc[test_idxs].copy()\n",
    "df_features_train = df_features_standard_scaled.iloc[train_idxs].copy()\n",
    "df_label_test = df_label.iloc[test_idxs].copy()\n",
    "df_label_train = df_label.iloc[train_idxs].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    2921\n",
       "True     1103\n",
       "Name: mind_wandered_label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what is the ratio of the labels in the training data?\n",
    "df_label_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If not obvious, the labels (and hopefully data as well), now have had participant 1002-UM removed, there are less total trials than before.  \n",
    "The number of trials in the training data and labels is $2921 + 1103 = 4024$, so the 52 trials of participant 1002-UM have been removed.  The data\n",
    "still has the roughly 28%/72% imbalance.\n",
    "\n",
    "Scikit-learn provides a mechanism to downsample the majority class, though this is a relatively simple procedure we could do ourself.  Actually as\n",
    "of this project, the imbalance-learn is a community project of scikit-learn, I suppose it will get folded into scikit-learn proper at some point.\n",
    "\n",
    "Downsampling the majority usually is done by removing without replacement items in the features (and the corresponding label) at random, in the paper we are\n",
    "replicating.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports needed for this section of the notebook\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "undersample = RandomUnderSampler(random_state=0)\n",
    "df_features_train_resampled, df_label_train_resampled = undersample.fit_resample(df_features_train, df_label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    1103\n",
       "True     1103\n",
       "Name: mind_wandered_label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label_train_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So fairly simple operation, the default behavior is to downsample until the classes are equalized.\n",
    "\n",
    "This should work in our leave-one-participant-out training loop.  For example, to get the next train/test iteration, we would do this again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    1113\n",
       "True     1113\n",
       "Name: mind_wandered_label, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# leave out the next participant\n",
    "train_idxs, test_idxs = next(logo_generator)\n",
    "\n",
    "# split the participant to test out and leave train data with rest of data\n",
    "df_features_test = df_features_standard_scaled.iloc[test_idxs].copy()\n",
    "df_features_train = df_features_standard_scaled.iloc[train_idxs].copy()\n",
    "df_label_test = df_label.iloc[test_idxs].copy()\n",
    "df_label_train = df_label.iloc[train_idxs].copy()\n",
    "\n",
    "# perform downsampling on this set of training data\n",
    "df_features_train_resampled, df_label_train_resampled = undersample.fit_resample(df_features_train, df_label_train)\n",
    "\n",
    "# see the result\n",
    "df_label_train_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minority Class Upsampling using SMOTE\n",
    "\n",
    "Conceptually the upsampling is much more complicated.  This is a data generation technique.  A good quick overview is\n",
    "[SMOTE for Imbalanced Classification](https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/)\n",
    "\n",
    "But using SMOTE upscaling from the `imbalance-learn` library will work pretty much the same as random downsampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports needed for this section of the notebook\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "logo = LeaveOneGroupOut()\n",
    "logo_generator = logo.split(df_features_standard_scaled, df_label, groups=participant_id)\n",
    "train_idxs, test_idxs = next(logo_generator)\n",
    "\n",
    "df_features_test = df_features_standard_scaled.iloc[test_idxs].copy()\n",
    "df_features_train = df_features_standard_scaled.iloc[train_idxs].copy()\n",
    "df_label_test = df_label.iloc[test_idxs].copy()\n",
    "df_label_train = df_label.iloc[train_idxs].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = SMOTE(random_state=0)\n",
    "df_features_train_resampled, df_label_train_resampled = oversample.fit_resample(df_features_train, df_label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    2921\n",
       "True     2921\n",
       "Name: mind_wandered_label, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label_train_resampled.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oversample for the next leave-one-out train/test split\n",
    "train_idxs, test_idxs = next(logo_generator)\n",
    "\n",
    "df_features_test = df_features_standard_scaled.iloc[test_idxs].copy()\n",
    "df_features_train = df_features_standard_scaled.iloc[train_idxs].copy()\n",
    "df_label_test = df_label.iloc[test_idxs].copy()\n",
    "df_label_train = df_label.iloc[train_idxs].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = SMOTE(random_state=0)\n",
    "df_features_train_resampled, df_label_train_resampled = oversample.fit_resample(df_features_train, df_label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    2913\n",
       "True     2913\n",
       "Name: mind_wandered_label, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label_train_resampled.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
