{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- mean_test_auc_roc using Logistic Regression:\n",
    "- mean_test_auc_roc using KNN:0.631033\n",
    "- mean_test_auc_roc using SVM:0.658805\n",
    "- mean_test_auc_roc using Random Forest:0.657398\n",
    "- mean_test_auc_roc using Decision Tree:0.640888\n",
    "- mean_test_auc_roc using **Naive Bayes:0.659468**\n",
    "- mean_test_auc_roc using Neural Network(Adam):0.634302\n",
    "- mean_test_auc_roc using Neural Network(SGD):0.630862\n",
    "- mean_test_auc_roc using Neural Network(RMSprop):0.629448"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globally useful imports of standard libraries needed in this notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path\n",
    "from datetime import datetime\n",
    "\n",
    "# specific libraries or classes needed for the work in this notebook\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.linear_model import LogisticRegressionCV\n",
    "#from sklearn.svm import SVC\n",
    "#from sklearn.naive_bayes import GaussianNB\n",
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, chi2, SelectFpr, f_regression, mutual_info_classif\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "#from sklearn.pipeline import Pipeline\n",
    "# need to use Pipeline from imblearn to add in a downsample or upsample\n",
    "# to cross validation training\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# import project specific modules used in this notebook\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "import mindwandering.data\n",
    "import mindwandering.features\n",
    "import mindwandering.evaluate\n",
    "from mindwandering.data import FeatureScalerTransformer\n",
    "from mindwandering.data import WinsorizationOutlierTransformer\n",
    "from mindwandering.data import VIFThresholdTransformer\n",
    "from mindwandering.data import FeatureSelectionTransformer\n",
    "from mindwandering.data import ClassImbalanceTransformer\n",
    "from mindwandering.data import GridSearchProgressHack\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, Dropout, BatchNormalization,Flatten\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.optimizers import SGD,Adam,RMSprop\n",
    "from tensorflow.keras.layers import Conv1D,GRU,TimeDistributed,MaxPooling1D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import AveragePooling1D,ZeroPadding1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data and Features\n",
    "df_features = mindwandering.data.get_df_features()\n",
    "mind_wandered_label = mindwandering.data.get_mind_wandered_label()\n",
    "participant_ids = mindwandering.data.get_participant_ids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "df_features=scaler.fit_transform(df_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select k-best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.feature_selection import SelectKBest,f_classif\n",
    "#k=[12,15,18,21,24,31]\n",
    "df_features = SelectKBest(f_classif,k=12).fit_transform(df_features,mind_wandered_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#participant_ids=participant_ids[:2193]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#participant_ids=participant_ids[:3300]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Allknn undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import AllKNN\n",
    "#df_features=df_features.values.reshape(-1, 1)\n",
    "allknn = AllKNN()\n",
    "df_features, mind_wandered_label = allknn.fit_resample(df_features, mind_wandered_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTEENN Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from imblearn.combine import SMOTEENN\\nsme = SMOTEENN(random_state=42)\\ndf_features, mind_wandered_label = sme.fit_resample(df_features, mind_wandered_label)'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from imblearn.combine import SMOTEENN\n",
    "sme = SMOTEENN(random_state=42)\n",
    "df_features, mind_wandered_label = sme.fit_resample(df_features, mind_wandered_label)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2193,)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mind_wandered_label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Reshape for conv1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2193, 12, 1)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_features = df_features.to_numpy()\n",
    "df_features1=df_features.reshape((df_features.shape[0], df_features.shape[1], 1))\n",
    "df_features1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from sklearn.model_selection import train_test_split\\nX_train, X_test, y_train, y_test = train_test_split(df_features, mind_wandered_label, test_size=0.33, random_state=42)'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_features, mind_wandered_label, test_size=0.33, random_state=42)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "auc_roc = tensorflow.keras.metrics.AUC(name='auc_roc',num_thresholds=20000,curve='ROC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"model = Sequential([\\n    Conv1D(filters=64, kernel_size=5,strides=1, activation='tanh',padding='causal', input_shape=(df_features.shape[1], 1),name='Conv1'),\\n    #ZeroPadding1D(padding=1),\\n    Flatten(name='Flatten1'),\\n    Dense(32, activation='relu',name='Dense1'),\\n    Dense(1, activation='swish',name='Dense2'),\\n    Activation('sigmoid',name='OutputLayer')])\\nmodel.compile(loss='binary_crossentropy',\\n              optimizer=SGD(lr=0.001),\\n              metrics=['accuracy', auc_roc])\\n\""
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"model = Sequential([\n",
    "    Conv1D(filters=64, kernel_size=5,strides=1, activation='tanh',padding='causal', input_shape=(df_features.shape[1], 1),name='Conv1'),\n",
    "    #ZeroPadding1D(padding=1),\n",
    "    Flatten(name='Flatten1'),\n",
    "    Dense(32, activation='relu',name='Dense1'),\n",
    "    Dense(1, activation='swish',name='Dense2'),\n",
    "    Activation('sigmoid',name='OutputLayer')])\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=SGD(lr=0.001),\n",
    "              metrics=['accuracy', auc_roc])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model.fit(X_train, y_train, epochs=1,verbose=1, validation_data=(X_test, y_test))'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"model.fit(X_train, y_train, epochs=1,verbose=1, validation_data=(X_test, y_test))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model.summary()'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"model.summary()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from tensorflow.keras.utils import plot_model\\nplot_model(model, to_file='model_conv_plot.png', show_shapes=True, show_layer_names=True)\""
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from tensorflow.keras.utils import plot_model\n",
    "plot_model(model, to_file='model_conv_plot.png', show_shapes=True, show_layer_names=True)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conv1d Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **ZeroPadding1D** layer is added after the input layer to add zeros at the beginning and end of each series. Zero-padding ensures that the convolution layer does not reduce the dimension of the output sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add a Conv1D layer. The first argument of Conv1D is the number of filters, which determine the number of features in the output. The second argument indicates the length of the 1D convolution window. The third argument is strides and represents the number of places to shift the convolution window. Lastly, though we haven't used it here, setting use_bias as True adds a bias value during the computation of an output feature. Here, the 1D convolution can be thought of as generating local MW models over a rolling window of Five time units."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From tensorflow doc: \n",
    "\n",
    "Padding: One of \"valid\", \"same\" or \"causal\" (case-insensitive). \"valid\" means no padding. \"same\" results in padding with zeros evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input. \"causal\" results in causal (dilated) convolutions, e.g. output[t] does not depend on input[t+1:]. Useful when modeling temporal data where the model should not violate the temporal order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(filters=64,kernel_size=5,optimizer=SGD(lr=0.001)):\n",
    "    model = Sequential([\n",
    "    Conv1D(filters=filters, kernel_size=kernel_size,strides=1, activation='tanh',padding='causal', input_shape=(df_features1.shape[1], 1)),\n",
    "    ZeroPadding1D(padding=1),\n",
    "    Flatten(),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='swish'),\n",
    "    Activation('sigmoid')])\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy', auc_roc])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap Keras model so it can be used by scikit-learn\n",
    "#kears_estimator = KerasClassifier(build_fn=create_model,epochs=100, batch_size=32, verbose=1)\n",
    "kears_estimator = KerasClassifier(build_fn=create_model,epochs=50, batch_size=32, verbose=1)\n",
    "#kears_estimator = KerasClassifier(build_fn=create_model, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 192 candidates, totalling 960 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The 'groups' parameter should not be None.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-3cbd0f971849>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;31m#search.fit(df_features, mind_wandered_label, groups=participant_ids)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0msearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmind_wandered_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    839\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1286\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1288\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    805\u001b[0m                                                        **fit_and_score_kwargs)\n\u001b[1;32m    806\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcand_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m                                    (split_idx, (train, test)) in product(\n\u001b[0m\u001b[1;32m    808\u001b[0m                                    \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m                                    enumerate(cv.split(X, y, groups))))\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    330\u001b[0m                 .format(self.n_splits, n_samples))\n\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_test_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m             \u001b[0mtrain_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_not\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mtest_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_iter_test_masks\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mBy\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelegates\u001b[0m \u001b[0mto\u001b[0m \u001b[0m_iter_test_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \"\"\"\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_test_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m             \u001b[0mtest_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0mtest_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_iter_test_indices\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_iter_test_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The 'groups' parameter should not be None.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m         \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The 'groups' parameter should not be None."
     ]
    }
   ],
   "source": [
    "\n",
    "# Empty dataframe to gather grid search results into 1 place\n",
    "best_estimator = None\n",
    "best_score = 0.0\n",
    "best_params = {}\n",
    "best_index = 0\n",
    "df_result = None\n",
    "\n",
    "\n",
    "parameters = {\n",
    "        #'scaling__type_of_scaling': ['standard'],\n",
    "        #'outlier__outlier_threshold': [0.0, 3.0],\n",
    "        #'features__k': [12,15],\n",
    "        #'balance__balancer_type': ['random-undersampler', 'allknn', 'nearmiss', 'instance-hardness-threshold'],\n",
    "        #'balance__balancer_type': ['allknn', 'condensed-nn', 'neighbourhood-cleaning', 'one-sided-selection'],\n",
    "        #'balance__balancer_type': ['allknn', 'one-sided-selection'],\n",
    "        #'balance__balancer_type': ['allknn', 'smote-enn'],\n",
    "        #'model__var_smoothing': [1e-6,1e-7,1e-8,1e-9,1e-10,1e-11,1e-12],\n",
    "        'model__batch_size': [32, 48],#usually multiple of 8\n",
    "        'model__epochs':[50,60],\n",
    "        'model__filters':[8,16,32,64],\n",
    "        'model__kernel_size':[3,5,7],\n",
    "        #'model__batch_size': [60],\n",
    "        #'model__epochs':[10],\n",
    "        'model__optimizer' : ['RMSprop', 'Adagrad', 'Adadelta','Adam']\n",
    "    }\n",
    "\n",
    "# Estimator Pipeline\n",
    "pipeline = Pipeline(\n",
    "      [\n",
    "        #('progress', GridSearchProgressHack(verbose=False)),\n",
    "        #('scaling',  FeatureScalerTransformer()),\n",
    "        #('outlier',  WinsorizationOutlierTransformer()),\n",
    "        #('features', SelectKBest()),\n",
    "        #('features', SelectFromModel(estimator=LogisticRegression(solver='liblinear', penalty='l1', C=0.1), threshold=-np.inf)),\n",
    "        #('balance',  ClassImbalanceTransformer()),\n",
    "        ('model',    kears_estimator)\n",
    "      ]\n",
    "    )\n",
    "    \n",
    "# Cross Validation Splitter\n",
    "cv_group_splitter = GroupKFold(n_splits=5)\n",
    "    #cv_group_splitter = LeaveOneGroupOut()\n",
    "\n",
    "    # perform the grid search for this vif selection\n",
    "    # set up the search\n",
    "search = GridSearchCV(\n",
    "        estimator = pipeline,\n",
    "        param_grid = parameters,\n",
    "        scoring = ['roc_auc','accuracy'],\n",
    "        cv = cv_group_splitter,\n",
    "        #cv = 5,\n",
    "        refit = 'roc_auc',\n",
    "        verbose = 1)\n",
    "\n",
    "search.fit(df_features, mind_wandered_label, groups=participant_ids)\n",
    "#search.fit(df_features, mind_wandered_label)\n",
    "\n",
    "df = pd.DataFrame(data=search.cv_results_)\n",
    "    \n",
    "    \n",
    "if best_estimator is None:\n",
    "    df_result = df\n",
    "    best_estimator = search.best_estimator_\n",
    "    best_score = search.best_score_\n",
    "    best_params = search.best_params_\n",
    "    best_index = search.best_index_\n",
    "else:\n",
    "    df_result = df_result.append(df, ignore_index=True)\n",
    "    if search.best_score_ > best_score:\n",
    "        best_estimator = search.best_estimator_\n",
    "        best_score = search.best_score_\n",
    "        best_params = search.best_params_\n",
    "        best_index = search.best_index_  # todo this is only the index of this search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 20 performers by the test_roc_auc score\n",
    "#,'param_model__max_features'\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "#res_cols = ['mean_test_roc_auc', 'mean_test_accuracy', 'param_balance__balancer_type', 'param_features__k', \n",
    "#            'param_features__score_func', 'param_model__C', 'param_model__solver', \n",
    "#            'param_outlier__outlier_threshold', 'param__vif_score_threshold']\n",
    "#res_cols = ['mean_test_roc_auc','mean_test_accuracy', 'param_balance__balancer_type', 'param_model__batch_size','param_model__epochs',\n",
    "            #'param_outlier__outlier_threshold']\n",
    "#res_cols = ['mean_test_roc_auc','mean_test_accuracy','model__batch_size','param_model__epochs','model__filters','model__kernel_size']\n",
    "res_cols = ['mean_test_roc_auc','mean_test_accuracy','param_model__batch_size','param_model__epochs','param_model__filters','param_model__kernel_size','param_model__optimizer']\n",
    "#res_cols = ['mean_test_roc_auc','mean_test_accuracy', 'param_balance__balancer_type','param_model__optimizer',\n",
    "            #'param_outlier__outlier_threshold']\n",
    "df_sorted = df_result[res_cols].reset_index(drop=True).sort_values('mean_test_roc_auc', axis=0, ascending=False)\n",
    "df_sorted.index = pd.RangeIndex(1, len(df_sorted.index)+1)\n",
    "df_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the average roc-auc and accuracy scores of just completed search.\n",
    "# these are the averages of each model over the convolution folds.\n",
    "#print(df_result['mean_test_roc_auc'])\n",
    "#print(df_result['mean_test_accuracy'])\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display results for the best estimator we found\n",
    "predictions = best_estimator.predict(df_features)\n",
    "probabilities = best_estimator.predict_proba(df_features)[:,1]\n",
    "mindwandering.evaluate.evaluate_model_results(mind_wandered_label, predictions, probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results and preliminary figures in the following cells\n",
    "\n",
    "# create base save file name for this file, use datetime to keep a unique file name\n",
    "now = datetime.now()\n",
    "date_time = now.strftime('%Y%m%d-%H%M')\n",
    "result_file_basename = 'replication-07-Neural-Network-using-Conv1D-varying-optimizer-undersampling' + date_time\n",
    "print(result_file_basename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A quick histogram of this search auc-roc scores.  Basically the figure 1 from the paper.\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "#bins = np.linspace(0.605, 0.612, 8)\n",
    "plt.hist(df_result.mean_test_roc_auc, \n",
    "         bins=20,\n",
    "         color='lightblue',\n",
    "         rwidth=0.9);\n",
    "#plt.xlabel('Area under the receiver operating characteristic (AUC-ROC)');\n",
    "plt.xlabel('Area under the receiver operating characteristic (AUC-ROC)');\n",
    "plt.ylabel('Number of models');\n",
    "plt.title('Neural Network Replication using conv1d for Undersampling Dataset: ' + result_file_basename);\n",
    "\n",
    "result_dir = '../figures'\n",
    "result_file_name = result_file_basename + '.eps'\n",
    "result_file_path = os.path.join(result_dir, result_file_name)\n",
    "plt.savefig(result_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the search results dataframe to a file so can retrieve for later data analysis or\n",
    "# to combine with other grid search results for summaries\n",
    "result_dir = '../DeepLearningResults'\n",
    "result_file_name = result_file_basename + '.pkl'\n",
    "result_file_path = os.path.join(result_dir, result_file_name)\n",
    "df_result.to_pickle(result_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
