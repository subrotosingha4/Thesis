{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- mean_test_auc_roc using Logistic Regression:\n",
    "- mean_test_auc_roc using KNN:0.631033\n",
    "- mean_test_auc_roc using SVM:0.658805\n",
    "- mean_test_auc_roc using Random Forest:0.657398\n",
    "- mean_test_auc_roc using Decision Tree:0.640888\n",
    "- mean_test_auc_roc using **Naive Bayes:0.659468**\n",
    "- mean_test_auc_roc using Neural Network(Adam):0.634302\n",
    "- mean_test_auc_roc using Neural Network(SGD):0.630862\n",
    "- mean_test_auc_roc using Neural Network(RMSprop):0.629448"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globally useful imports of standard libraries needed in this notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path\n",
    "from datetime import datetime\n",
    "\n",
    "# specific libraries or classes needed for the work in this notebook\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.linear_model import LogisticRegressionCV\n",
    "#from sklearn.svm import SVC\n",
    "#from sklearn.naive_bayes import GaussianNB\n",
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, chi2, SelectFpr, f_regression, mutual_info_classif\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "#from sklearn.pipeline import Pipeline\n",
    "# need to use Pipeline from imblearn to add in a downsample or upsample\n",
    "# to cross validation training\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# import project specific modules used in this notebook\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "import mindwandering.data\n",
    "import mindwandering.features\n",
    "import mindwandering.evaluate\n",
    "from mindwandering.data import FeatureScalerTransformer\n",
    "from mindwandering.data import WinsorizationOutlierTransformer\n",
    "from mindwandering.data import VIFThresholdTransformer\n",
    "from mindwandering.data import FeatureSelectionTransformer\n",
    "from mindwandering.data import ClassImbalanceTransformer\n",
    "from mindwandering.data import GridSearchProgressHack\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, Dropout, BatchNormalization,Flatten\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.optimizers import SGD,Adam,RMSprop\n",
    "from tensorflow.keras.layers import Conv1D,GRU,TimeDistributed,MaxPooling1D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import AveragePooling1D,ZeroPadding1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data and Features\n",
    "df_features = mindwandering.data.get_df_features()\n",
    "mind_wandered_label = mindwandering.data.get_mind_wandered_label()\n",
    "participant_ids = mindwandering.data.get_participant_ids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "df_features=scaler.fit_transform(df_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select k-best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.feature_selection import SelectKBest,f_classif\n",
    "#k=[12,15,18,21,24,31]\n",
    "df_features = SelectKBest(f_classif,k=12).fit_transform(df_features,mind_wandered_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#participant_ids=participant_ids[:2193]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#participant_ids=participant_ids[:3300]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Allknn undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import AllKNN\n",
    "#df_features=df_features.values.reshape(-1, 1)\n",
    "allknn = AllKNN()\n",
    "df_features, mind_wandered_label = allknn.fit_resample(df_features, mind_wandered_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTEENN Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from imblearn.combine import SMOTEENN\\nsme = SMOTEENN(random_state=42)\\ndf_features, mind_wandered_label = sme.fit_resample(df_features, mind_wandered_label)'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from imblearn.combine import SMOTEENN\n",
    "sme = SMOTEENN(random_state=42)\n",
    "df_features, mind_wandered_label = sme.fit_resample(df_features, mind_wandered_label)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2193,)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mind_wandered_label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Reshape for conv1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2193, 12, 1)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_features = df_features.to_numpy()\n",
    "df_features1=df_features.reshape((df_features.shape[0], df_features.shape[1], 1))\n",
    "df_features1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from sklearn.model_selection import train_test_split\\nX_train, X_test, y_train, y_test = train_test_split(df_features, mind_wandered_label, test_size=0.33, random_state=42)'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_features, mind_wandered_label, test_size=0.33, random_state=42)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "auc_roc = tensorflow.keras.metrics.AUC(name='auc_roc',num_thresholds=20000,curve='ROC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"model = Sequential([\\n    Conv1D(filters=64, kernel_size=5,strides=1, activation='tanh',padding='causal', input_shape=(df_features.shape[1], 1),name='Conv1'),\\n    #ZeroPadding1D(padding=1),\\n    Flatten(name='Flatten1'),\\n    Dense(32, activation='relu',name='Dense1'),\\n    Dense(1, activation='swish',name='Dense2'),\\n    Activation('sigmoid',name='OutputLayer')])\\nmodel.compile(loss='binary_crossentropy',\\n              optimizer=SGD(lr=0.001),\\n              metrics=['accuracy', auc_roc])\\n\""
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"model = Sequential([\n",
    "    Conv1D(filters=64, kernel_size=5,strides=1, activation='tanh',padding='causal', input_shape=(df_features.shape[1], 1),name='Conv1'),\n",
    "    #ZeroPadding1D(padding=1),\n",
    "    Flatten(name='Flatten1'),\n",
    "    Dense(32, activation='relu',name='Dense1'),\n",
    "    Dense(1, activation='swish',name='Dense2'),\n",
    "    Activation('sigmoid',name='OutputLayer')])\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=SGD(lr=0.001),\n",
    "              metrics=['accuracy', auc_roc])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model.fit(X_train, y_train, epochs=1,verbose=1, validation_data=(X_test, y_test))'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"model.fit(X_train, y_train, epochs=1,verbose=1, validation_data=(X_test, y_test))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model.summary()'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"model.summary()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from tensorflow.keras.utils import plot_model\\nplot_model(model, to_file='model_conv_plot.png', show_shapes=True, show_layer_names=True)\""
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from tensorflow.keras.utils import plot_model\n",
    "plot_model(model, to_file='model_conv_plot.png', show_shapes=True, show_layer_names=True)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conv1d Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **ZeroPadding1D** layer is added after the input layer to add zeros at the beginning and end of each series. Zero-padding ensures that the convolution layer does not reduce the dimension of the output sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add a Conv1D layer. The first argument of Conv1D is the number of filters, which determine the number of features in the output. The second argument indicates the length of the 1D convolution window. The third argument is strides and represents the number of places to shift the convolution window. Lastly, though we haven't used it here, setting use_bias as True adds a bias value during the computation of an output feature. Here, the 1D convolution can be thought of as generating local MW models over a rolling window of Five time units."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From tensorflow doc: \n",
    "\n",
    "Padding: One of \"valid\", \"same\" or \"causal\" (case-insensitive). \"valid\" means no padding. \"same\" results in padding with zeros evenly to the left/right or up/down of the input such that output has the same height/width dimension as the input. \"causal\" results in causal (dilated) convolutions, e.g. output[t] does not depend on input[t+1:]. Useful when modeling temporal data where the model should not violate the temporal order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(filters=64,kernel_size=5,optimizer=SGD(lr=0.001)):\n",
    "    model = Sequential([\n",
    "    Conv1D(filters=filters, kernel_size=kernel_size,strides=1, activation='tanh',padding='causal', input_shape=(df_features1.shape[1], 1)),\n",
    "    ZeroPadding1D(padding=1),\n",
    "    Flatten(),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='swish'),\n",
    "    Activation('sigmoid')])\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy', auc_roc])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap Keras model so it can be used by scikit-learn\n",
    "#kears_estimator = KerasClassifier(build_fn=create_model,epochs=100, batch_size=32, verbose=1)\n",
    "kears_estimator = KerasClassifier(build_fn=create_model,epochs=50, batch_size=32, verbose=1)\n",
    "#kears_estimator = KerasClassifier(build_fn=create_model, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [2193, 2193, 4076]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-d21fd2548907>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m         verbose = 1)\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0msearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmind_wandered_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparticipant_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;31m#search.fit(df_features, mind_wandered_label)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0mrefit_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m         \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_fit_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    297\u001b[0m     \"\"\"\n\u001b[1;32m    298\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[1;32m    263\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [2193, 2193, 4076]"
     ]
    }
   ],
   "source": [
    "\n",
    "# Empty dataframe to gather grid search results into 1 place\n",
    "best_estimator = None\n",
    "best_score = 0.0\n",
    "best_params = {}\n",
    "best_index = 0\n",
    "df_result = None\n",
    "\n",
    "\n",
    "parameters = {\n",
    "        #'scaling__type_of_scaling': ['standard'],\n",
    "        #'outlier__outlier_threshold': [0.0, 3.0],\n",
    "        #'features__k': [12,15],\n",
    "        #'balance__balancer_type': ['random-undersampler', 'allknn', 'nearmiss', 'instance-hardness-threshold'],\n",
    "        #'balance__balancer_type': ['allknn', 'condensed-nn', 'neighbourhood-cleaning', 'one-sided-selection'],\n",
    "        #'balance__balancer_type': ['allknn', 'one-sided-selection'],\n",
    "        #'balance__balancer_type': ['allknn', 'smote-enn'],\n",
    "        #'model__var_smoothing': [1e-6,1e-7,1e-8,1e-9,1e-10,1e-11,1e-12],\n",
    "        'model__batch_size': [32, 48],#usually multiple of 8\n",
    "        'model__epochs':[50,60],\n",
    "        'model__filters':[8,16,32,64],\n",
    "        'model__kernel_size':[3,5,7],\n",
    "        #'model__batch_size': [60],\n",
    "        #'model__epochs':[10],\n",
    "        'model__optimizer' : ['RMSprop', 'Adagrad', 'Adadelta','Adam']\n",
    "    }\n",
    "\n",
    "# Estimator Pipeline\n",
    "pipeline = Pipeline(\n",
    "      [\n",
    "        #('progress', GridSearchProgressHack(verbose=False)),\n",
    "        #('scaling',  FeatureScalerTransformer()),\n",
    "        #('outlier',  WinsorizationOutlierTransformer()),\n",
    "        #('features', SelectKBest()),\n",
    "        #('features', SelectFromModel(estimator=LogisticRegression(solver='liblinear', penalty='l1', C=0.1), threshold=-np.inf)),\n",
    "        #('balance',  ClassImbalanceTransformer()),\n",
    "        ('model',    kears_estimator)\n",
    "      ]\n",
    "    )\n",
    "    \n",
    "# Cross Validation Splitter\n",
    "cv_group_splitter = GroupKFold(n_splits=5)\n",
    "    #cv_group_splitter = LeaveOneGroupOut()\n",
    "\n",
    "    # perform the grid search for this vif selection\n",
    "    # set up the search\n",
    "search = GridSearchCV(\n",
    "        estimator = pipeline,\n",
    "        param_grid = parameters,\n",
    "        scoring = ['roc_auc','accuracy'],\n",
    "        cv = cv_group_splitter,\n",
    "        #cv = 5,\n",
    "        refit = 'roc_auc',\n",
    "        verbose = 1)\n",
    "\n",
    "search.fit(df_features, mind_wandered_label, groups=participant_ids)\n",
    "#search.fit(df_features, mind_wandered_label)\n",
    "\n",
    "df = pd.DataFrame(data=search.cv_results_)\n",
    "    \n",
    "    \n",
    "if best_estimator is None:\n",
    "    df_result = df\n",
    "    best_estimator = search.best_estimator_\n",
    "    best_score = search.best_score_\n",
    "    best_params = search.best_params_\n",
    "    best_index = search.best_index_\n",
    "else:\n",
    "    df_result = df_result.append(df, ignore_index=True)\n",
    "    if search.best_score_ > best_score:\n",
    "        best_estimator = search.best_estimator_\n",
    "        best_score = search.best_score_\n",
    "        best_params = search.best_params_\n",
    "        best_index = search.best_index_  # todo this is only the index of this search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 20 performers by the test_roc_auc score\n",
    "#,'param_model__max_features'\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "#res_cols = ['mean_test_roc_auc', 'mean_test_accuracy', 'param_balance__balancer_type', 'param_features__k', \n",
    "#            'param_features__score_func', 'param_model__C', 'param_model__solver', \n",
    "#            'param_outlier__outlier_threshold', 'param__vif_score_threshold']\n",
    "#res_cols = ['mean_test_roc_auc','mean_test_accuracy', 'param_balance__balancer_type', 'param_model__batch_size','param_model__epochs',\n",
    "            #'param_outlier__outlier_threshold']\n",
    "#res_cols = ['mean_test_roc_auc','mean_test_accuracy','model__batch_size','param_model__epochs','model__filters','model__kernel_size']\n",
    "res_cols = ['mean_test_roc_auc','mean_test_accuracy','param_model__batch_size','param_model__epochs','param_model__filters','param_model__kernel_size','param_model__optimizer']\n",
    "#res_cols = ['mean_test_roc_auc','mean_test_accuracy', 'param_balance__balancer_type','param_model__optimizer',\n",
    "            #'param_outlier__outlier_threshold']\n",
    "df_sorted = df_result[res_cols].reset_index(drop=True).sort_values('mean_test_roc_auc', axis=0, ascending=False)\n",
    "df_sorted.index = pd.RangeIndex(1, len(df_sorted.index)+1)\n",
    "df_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the average roc-auc and accuracy scores of just completed search.\n",
    "# these are the averages of each model over the convolution folds.\n",
    "#print(df_result['mean_test_roc_auc'])\n",
    "#print(df_result['mean_test_accuracy'])\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display results for the best estimator we found\n",
    "predictions = best_estimator.predict(df_features)\n",
    "probabilities = best_estimator.predict_proba(df_features)[:,1]\n",
    "mindwandering.evaluate.evaluate_model_results(mind_wandered_label, predictions, probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results and preliminary figures in the following cells\n",
    "\n",
    "# create base save file name for this file, use datetime to keep a unique file name\n",
    "now = datetime.now()\n",
    "date_time = now.strftime('%Y%m%d-%H%M')\n",
    "result_file_basename = 'replication-07-Neural-Network-using-Conv1D-varying-optimizer-undersampling' + date_time\n",
    "print(result_file_basename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A quick histogram of this search auc-roc scores.  Basically the figure 1 from the paper.\n",
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "#bins = np.linspace(0.605, 0.612, 8)\n",
    "plt.hist(df_result.mean_test_roc_auc, \n",
    "         bins=20,\n",
    "         color='lightblue',\n",
    "         rwidth=0.9);\n",
    "#plt.xlabel('Area under the receiver operating characteristic (AUC-ROC)');\n",
    "plt.xlabel('Area under the receiver operating characteristic (AUC-ROC)');\n",
    "plt.ylabel('Number of models');\n",
    "plt.title('Neural Network Replication using conv1d for Undersampling Dataset: ' + result_file_basename);\n",
    "\n",
    "result_dir = '../figures'\n",
    "result_file_name = result_file_basename + '.eps'\n",
    "result_file_path = os.path.join(result_dir, result_file_name)\n",
    "plt.savefig(result_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the search results dataframe to a file so can retrieve for later data analysis or\n",
    "# to combine with other grid search results for summaries\n",
    "result_dir = '../DeepLearningResults'\n",
    "result_file_name = result_file_basename + '.pkl'\n",
    "result_file_path = os.path.join(result_dir, result_file_name)\n",
    "df_result.to_pickle(result_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
